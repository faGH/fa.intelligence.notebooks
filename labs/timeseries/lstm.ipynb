{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Time Series Forecasting with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_file_path = './data/featurized_market_data.p'\n",
    "\n",
    "with open(model_file_path, 'rb') as fp:\n",
    "    featurized_market_data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate time from the rest of the data.\n",
    "pair_name = 'AAVE_BTC'\n",
    "features = featurized_market_data[pair_name].dropna().set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data.\n",
    "## LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized.\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(features)\n",
    "features_scaled = scaler.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and prediction sliding windowed buckets.\n",
    "features_current_past = []\n",
    "features_future = []\n",
    "\n",
    "# Count of steps to forecast into the future.\n",
    "n_future_step_count = 1\n",
    "# Count of steps to consider historically including the current step.\n",
    "n_past_step_count_inc_current = 24\n",
    "column_index_to_predict = 3\n",
    "\n",
    "for i in range(n_past_step_count_inc_current, len(features_scaled) - n_future_step_count + 1):\n",
    "    features_current_past.append(features_scaled[i - n_past_step_count_inc_current : i])\n",
    "    features_future.append(features_scaled[i + n_future_step_count - 1 : i + n_future_step_count, column_index_to_predict])\n",
    "    \n",
    "features_current_past, features_future = np.array(features_current_past), np.array(features_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past Window Shape: (8802, 24, 35)\n",
      "Future Window Shape: (8802, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'Past Window Shape: {features_current_past.shape}')\n",
    "print(f'Future Window Shape: {features_future.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_inspect = 0\n",
    "# -1 takes the last record in each windows (the current one of that window). Anything apart from -1 would be historical records for context / experience replay.\n",
    "most_recent_features = features_current_past[index_to_inspect + 1][-1]\n",
    "\n",
    "assert features_future[index_to_inspect] == most_recent_features[column_index_to_predict], 'The first future price should be the same as the following current price for the prediction column.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 24, 128)           83968     \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 24, 64)            49408     \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 145,825\n",
      "Trainable params: 145,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', recurrent_dropout=0.1, input_shape=(features_current_past.shape[1], features_current_past.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(64, activation='relu', recurrent_dropout=0.1, return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', recurrent_dropout=0.1, return_sequences=False))\n",
    "model.add(Dense(features_future.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "496/496 [==============================] - 37s 65ms/step - loss: 13.4378 - val_loss: 0.0059\n",
      "Epoch 2/150\n",
      "  1/496 [..............................] - ETA: 30s - loss: 0.0525"
     ]
    }
   ],
   "source": [
    "history = model.fit(features_current_past, features_future, epochs=1000, batch_size=n_past_step_count_inc_current, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Value Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_current_past[24-n_past_step_count_inc_current:24+1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_record_count = 24\n",
    "forecast_frequency = '1h'\n",
    "forecast = model.predict(features_current_past[-n_past_step_count_inc_current:])\n",
    "forecast_period_dates = pd.date_range(list(features.index)[-1], periods=forecast_record_count, freq=forecast_frequency).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_steps_to_visualize = 48\n",
    "historical_data = features.tail(historical_steps_to_visualize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inverse scaling.\n",
    "shaped_forecast = np.repeat(forecast, features.shape[1], axis=-1)\n",
    "scaled_forecasts = scaler.inverse_transform(shaped_forecast)[:, column_index_to_predict]\n",
    "forecast_df = pd.DataFrame({ 'time': np.array(forecast_period_dates), 'close': np.array(scaled_forecasts) }).set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for window in features_current_past[-historical_steps_to_visualize:]:\n",
    "    prediction_windows = []\n",
    "    prediction_windows.append(window)\n",
    "    prediction_windows = np.array(prediction_windows)\n",
    "    forecast = model.predict(prediction_windows)\n",
    "    shaped_forecast = np.repeat(forecast, features.shape[1], axis=-1)\n",
    "    scaled_forecast = scaler.inverse_transform(shaped_forecast)[:, column_index_to_predict]\n",
    "    predictions.append(scaled_forecast[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data_with_predictions = historical_data.copy()\n",
    "historical_data_with_predictions['predicted'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(pair_name)\n",
    "plt.plot(historical_data_with_predictions['close'], label='Historical', color='dodgerblue')\n",
    "plt.plot(historical_data_with_predictions['predicted'], color='magenta')\n",
    "plt.plot(forecast_df['close'], label='Forecasted', color='magenta')\n",
    "plt.xlabel('Time - 1h Candles')\n",
    "plt.ylabel('Close Price')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "- [Documentation](https://timeseriestransformer.readthedocs.io/en/latest/README.html)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c96ffff15f49694e20d6af92a59f54c1cf6ff4da4eb0cf9141168fba41748bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (Tensorflow)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
