{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crypto Pair Trading Environment\n",
    "### Overview\n",
    "A reinforcement learning environment for trading crypto pairs. This environment is targeted at trading a single pair. Find the crypto_exchance_trading_environment for a wrapper of this environment that allows for trading more than one kind of pair at a time.\n",
    "### Features\n",
    "- Allows for features / indicators / additional numerical data in the observation space.\n",
    "- Memory allows for the current timestep's observation space to have X length of historical data most recent to the current timestep.\n",
    "- Long-only positions as this is common in the crypto-world.\n",
    "- When buying stakes, max_stake_count of stakes are allowed however when selling, the environment sells all stakes at once.\n",
    "### References\n",
    "|Reference|Relevance|\n",
    "|--|--|\n",
    "|[OpenAI Gym Base](https://github.com/openai/gym/blob/master/gym/core.py)|The base class for our environment. This interface seems to be a standard in the reinforcement learning space.|\n",
    "|[AnyTrading Foundation](https://github.com/AminHP/gym-anytrading)|We used AnyTrading's work as a reference point for creating our own environment that's a little more talored to our needs.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Space\n",
    "This refers to the decisions / actions that can be applied to the environment. Usually decided by some intelligent system like a neural network or a state vector machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(Enum):\n",
    "    Hold = 0\n",
    "    Buy = 1\n",
    "    Sell = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price Movement\n",
    "This refers to the columns we can expect to be present always in the data. Open, close, high, low, volume and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceMovementColumns(Enum):\n",
    "    Time = 'time'\n",
    "    Open = 'open'\n",
    "    High = 'high'\n",
    "    Low = 'low'\n",
    "    Close = 'close'\n",
    "    Volume = 'volume'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions\n",
    "This refers to all the columns that we can expect to see in the transactions dataframe. This allows us to track all buys and sells over time. This dataframe is append-only and so we resort to joins to determine open transactions. This helps us in the long run to visualize performance and extend the enviroment's behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransactionsColumns(Enum):\n",
    "    PairName = 'pair_name'\n",
    "    Time = 'time_of_transaction'\n",
    "    Price = 'price_at_transaction_time'\n",
    "    Quantity = 'quantity'\n",
    "    IsBuy = 'is_buy_order'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Internal Observations\n",
    "These observations are appended to the data provided to the environment as to keep track of the environment's internal state and expose that to any wrapping model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InternalColumns(Enum):\n",
    "    OpenTransactionCount = '__open_transaction_count__'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryptoPairTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self, data, pair_name, max_stake_count=1, memory_window_size=50, seed=None, trading_fee_percentage=0.001):\n",
    "        assert data.ndim == 2, 'The price movement & features dataframe can only be an array of 2 dimensions (tabular).'\n",
    "        assert max_stake_count > 0, 'The max allowed stake units should be 1 or more. This allows for position stacking on a given pair. Stake amount for the first transaction would implicitly be total_profit/max_stake_count.'\n",
    "        assert memory_window_size > 0, 'The memory window should be 1 for no memory (only the most recent 1) or a positive number for a length of historical events to keep.'\n",
    "        assert data.shape[0] > memory_window_size, 'The provided data has to contain at least as many records as the length of the memory window.'\n",
    "        assert trading_fee_percentage > 0 and trading_fee_percentage < 1, 'A valid trading fee is required. Usually around 0.003 (0.3%).'\n",
    "        \n",
    "        self.seed(seed)\n",
    "        \n",
    "        # Persist locals.\n",
    "        self.pair_name = pair_name\n",
    "        self.data = self.__extend_data_columns_and_default_values__(data.fillna(0))\n",
    "        self.max_stake_count = max_stake_count\n",
    "        self.memory_window_size = memory_window_size\n",
    "        self.trading_fee_percentage = trading_fee_percentage\n",
    "        self.memory_shape = (self.memory_window_size, self.data.copy().drop(PriceMovementColumns.Time.value, 1).shape[1])\n",
    "        \n",
    "        # Define spaces. This can be thought of the input and output of any model we build around this environment.\n",
    "        self.action_space = spaces.Discrete(len(Actions))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=self.memory_shape, dtype=np.float32)\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def __extend_data_columns_and_default_values__(self, df):\n",
    "        result = df.copy()\n",
    "        \n",
    "        for internal_column in InternalColumns:\n",
    "            result[internal_column.value] = 0\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def __take_action__(self, action):\n",
    "        current_timestep = self.current_window[-1:]\n",
    "        open_transactions = self.__get_open_transactions__()\n",
    "        open_transactions_count = open_transactions.shape[0]\n",
    "        \n",
    "        if Actions(action) == Actions.Buy:\n",
    "            # Only allow for max_stake_count purchases.\n",
    "            positions_left_to_buy = self.max_stake_count - open_transactions_count\n",
    "            \n",
    "            if positions_left_to_buy > 0:\n",
    "                # Determine the quantity for a stake given how many stakes are still available.\n",
    "                stake_amount = self.balance / positions_left_to_buy\n",
    "                \n",
    "                # Make purchase.\n",
    "                self.transactions = self.transactions.append({\n",
    "                    TransactionsColumns.PairName.value: self.pair_name,\n",
    "                    #TransactionsColumns.Time.value: current_timestep[PriceMovementColumns.Time.value].values[0],\n",
    "                    TransactionsColumns.Price.value: current_timestep[PriceMovementColumns.Close.value].values[0],\n",
    "                    TransactionsColumns.Quantity.value: stake_amount,\n",
    "                    TransactionsColumns.IsBuy.value: True\n",
    "                }, ignore_index=True)\n",
    "                # Adjust base pair balance.\n",
    "                self.balance -= stake_amount\n",
    "        \n",
    "        if Actions(action) == Actions.Sell:\n",
    "            # Only sell when we have any open transactions.\n",
    "            if open_transactions_count > 0:\n",
    "                current_price = current_timestep[PriceMovementColumns.Close.value].values[0]\n",
    "                \n",
    "                # Sell all transactions at once.\n",
    "                for index, row in open_transactions.iterrows():\n",
    "                    quantity = row[TransactionsColumns.Quantity.value]\n",
    "                    \n",
    "                    # Calculate the profit for the respective transaction and add it to the running profit in the environment.\n",
    "                    self.balance += current_price * quantity\n",
    "                    # Make sell.\n",
    "                    self.transactions = self.transactions.append({\n",
    "                        TransactionsColumns.PairName.value: self.pair_name,\n",
    "                        #TransactionsColumns.Time.value: current_timestep[PriceMovementColumns.Time.value].values[0],\n",
    "                        TransactionsColumns.Price.value: current_timestep[PriceMovementColumns.Close.value].values[0],\n",
    "                        TransactionsColumns.Quantity.value: quantity,\n",
    "                        TransactionsColumns.IsBuy.value: False\n",
    "                    }, ignore_index=True)\n",
    "        \n",
    "        # Refresh open transactions after altering them.\n",
    "        if Actions(action) != Actions.Hold:\n",
    "            open_transactions = self.__get_open_transactions__()\n",
    "        \n",
    "        # On a hold, we simply return the rewards without changing the purchases data.\n",
    "        return self.__determine_reward__(open_transactions), open_transactions\n",
    "    \n",
    "    def __determine_reward__(self, open_transactions):\n",
    "        # Determine the reward for the balance (-1 that we started with).\n",
    "        balance_reward = self.balance - 1\n",
    "        \n",
    "        # Offset that balance by the profits of open transactions.\n",
    "        open_transactions_profits_reward = 0\n",
    "        current_price = self.current_window[-1:][PriceMovementColumns.Close.value].values[0]\n",
    "        \n",
    "        for index, open_transaction in open_transactions.iterrows():\n",
    "            ot_buy_price = open_transaction[TransactionsColumns.Price.value]\n",
    "            ot_qty = open_transaction[TransactionsColumns.Quantity.value]\n",
    "            # Calculate the different in price from when we purchased it. Multiply by how much we have to get total profit. Divide by allowed parallel transactions to normalize the reward cross-configuration.\n",
    "            ot_profit = ((current_price - ot_buy_price) * ot_qty / self.max_stake_count)\n",
    "            open_transactions_profits_reward += ot_profit\n",
    "            \n",
    "        open_transactions_profits_reward *= 10000\n",
    "        \n",
    "        # Update the episode's total running reward.\n",
    "        reward = balance_reward + open_transactions_profits_reward\n",
    "        self.total_reward += reward\n",
    "        \n",
    "        return reward\n",
    "    \n",
    "    def __determine_observation__(self, open_transactions):\n",
    "        # Configure internal features.\n",
    "        stakes_open = open_transactions.shape[0]\n",
    "        \n",
    "        # Perform the update on the entire dataframe as well as the current window.\n",
    "        self.data.at[self.current_window_end_index, InternalColumns.OpenTransactionCount.value] = stakes_open\n",
    "        self.current_window.at[-1, InternalColumns.OpenTransactionCount.value] = stakes_open\n",
    "        \n",
    "        return self.current_window.drop(PriceMovementColumns.Time.value, 1).to_numpy()\n",
    "    \n",
    "    def __determine_done__(self, open_transactions):\n",
    "        if self.current_window.shape[0] < self.memory_window_size:\n",
    "            print('Ran out of time. Environment is now done.')\n",
    "            return True\n",
    "\n",
    "        open_transaction_count = open_transactions.shape[0]\n",
    "        \n",
    "        if self.balance <= 0 and open_transaction_count <= 0:\n",
    "            print(f'Ran out of capital with {open_transaction_count} remaining open transactions. Environment is now done.')\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def __get_step_info__(self, open_transactions):\n",
    "        return {}\n",
    "        #return dict(\n",
    "        #    total_reward = self.total_reward,\n",
    "        #    balance = self.balance,\n",
    "        #    open_transactions = open_transactions\n",
    "        #)\n",
    "        \n",
    "    def __next_timestep__(self):\n",
    "        self.current_window_start_index += 1\n",
    "        self.current_window_end_index += 1\n",
    "        self.current_window = self.data[self.current_window_start_index:self.current_window_end_index]\n",
    "    \n",
    "    def __get_open_transactions__(self):\n",
    "        all_transactions = self.transactions\n",
    "        sell_transaction_indexes = all_transactions.index[all_transactions[TransactionsColumns.IsBuy.value] == False]\n",
    "        last_sold_transaction_index = sell_transaction_indexes[-1] if len(sell_transaction_indexes) > 0 else -1\n",
    "        first_open_transaction_index = last_sold_transaction_index + 1\n",
    "        open_transactions = all_transactions[first_open_transaction_index:]\n",
    "\n",
    "        return open_transactions\n",
    "    \n",
    "    def step(self, action):\n",
    "        step_reward, open_transactions = self.__take_action__(action)\n",
    "        observation = self.__determine_observation__(open_transactions)\n",
    "        info = self.__get_step_info__(open_transactions)\n",
    "        \n",
    "        self.__next_timestep__()\n",
    "        \n",
    "        done = self.__determine_done__(open_transactions)\n",
    "        \n",
    "        return observation, step_reward, done, info\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        \n",
    "        return [seed]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = self.__extend_data_columns_and_default_values__(self.data)\n",
    "        self.current_window_start_index = 0\n",
    "        self.current_window_end_index = self.memory_window_size\n",
    "        self.current_window = self.data[self.current_window_start_index:self.current_window_end_index]\n",
    "        self.total_reward = 0.\n",
    "        self.balance = 1.\n",
    "        self.transactions = pd.DataFrame(columns=[ ck.value for ck in TransactionsColumns ])\n",
    "\n",
    "        return self.current_window.drop(PriceMovementColumns.Time.value, 1).to_numpy()\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        assert mode == 'human', 'Currently only human-mode is supported for rendering with rgb_array support coming.'\n",
    "        \n",
    "        print(f'Rendering the environment results now. {self.data.shape[0]} close price points and {self.transactions.shape[0]} transaction points. This may take a while.')\n",
    "        plt.cla()\n",
    "        plt.plot(self.data[PriceMovementColumns.Time.value], self.data[PriceMovementColumns.Close.value])\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Close Price')\n",
    "        \n",
    "        # Draw an indicator for all transactions.\n",
    "        for index, transaction in self.transactions.iterrows():\n",
    "            color = 'green' if transaction[TransactionsColumns.IsBuy.value] == True else 'red'\n",
    "            tick = transaction[TransactionsColumns.Time.value]\n",
    "            close = transaction[TransactionsColumns.Price.value]\n",
    "            plt.scatter(tick, close, color=color)\n",
    "            \n",
    "        # If the account was depleted, render an indicator for when that happened.\n",
    "        if self.balance <= 0:\n",
    "            last_transaction = self.transactions[-1:]\n",
    "            last_transaction_time = last_transaction[TransactionsColumns.Time.value].values[0]\n",
    "            last_transaction_price = last_transaction[TransactionsColumns.Price.value].values[0]\n",
    "            plt.axvline(last_transaction_time, last_transaction_price, color='red')\n",
    "        \n",
    "        plt.title(self.pair_name)\n",
    "        plt.suptitle(\n",
    "            f'Total Reward: {self.total_reward} ~ Total Profit: {round((self.balance - 1) * 100, 2)}% ~ Steps: {self.current_window_start_index + 1}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c96ffff15f49694e20d6af92a59f54c1cf6ff4da4eb0cf9141168fba41748bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9 (Tensorflow)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
