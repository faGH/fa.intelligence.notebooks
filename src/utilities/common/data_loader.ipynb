{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as log\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    original_data: pd.DataFrame = None\n",
    "    labels_column_names: list = None\n",
    "    date_column_name: str = None\n",
    "    test_split: float = None\n",
    "    custom_featurizers: list = None\n",
    "    state_dict: dict = None\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, labels_column_names: list, date_column_name: str = None, test_split: float = 0.2):\n",
    "        self.original_data = data.copy()\n",
    "        self.labels_column_names = labels_column_names\n",
    "        self.date_column_name = date_column_name\n",
    "        self.test_split = test_split\n",
    "        self.custom_featurizers = list()\n",
    "        self.state_dict = {}\n",
    "\n",
    "        if len(data.columns) < 2:\n",
    "            raise Exception(f'The provided dataset should have at least 2 columns.')\n",
    "\n",
    "        if data.shape[1] <= 0:\n",
    "            raise Exception(f'The provided dataset should have at least 1 row.')\n",
    "\n",
    "        if len(labels_column_names) < 1:\n",
    "            raise Exception(f'The provided labels collection should have at least 1 label (column name to predict).')\n",
    "\n",
    "        for label_column_name in labels_column_names:\n",
    "            if label_column_name not in data.columns:\n",
    "                raise Exception(f'The provided label column \"{label_column_name}\" does not exist in the provided dataset.')\n",
    "\n",
    "        if date_column_name is not None and date_column_name not in data.columns:\n",
    "            raise Exception(f'The provided date column \"{date_column_name}\" does not exist in the provided dataset.')\n",
    "        \n",
    "        log.info('Validation of labels and date column (if provided) has been successful against the provided dataset.')\n",
    "\n",
    "    def __featurize_date_column__(self, data: pd.DataFrame, date_column_name: str) -> pd.DataFrame:\n",
    "        if self.date_column_name is None:\n",
    "            return data\n",
    "\n",
    "        __data__: pd.DataFrame = data.copy()\n",
    "        parsed_date_temporary_column = pd.to_datetime(__data__[date_column_name])\n",
    "        __data__ = __data__.drop(columns=[date_column_name], inplace=False)\n",
    "        __data__[f'{date_column_name}_year'] = parsed_date_temporary_column.dt.year\n",
    "        __data__[f'{date_column_name}_month'] = parsed_date_temporary_column.dt.month\n",
    "        __data__[f'{date_column_name}_day'] = parsed_date_temporary_column.dt.day\n",
    "        __data__[f'{date_column_name}_hour'] = parsed_date_temporary_column.dt.hour\n",
    "        __data__[f'{date_column_name}_am_or_pm'] = np.where(parsed_date_temporary_column.dt.hour < 12, 'am', 'pm')\n",
    "        __data__[f'{date_column_name}_minute'] = parsed_date_temporary_column.dt.minute\n",
    "        __data__[f'{date_column_name}_day_of_year'] = parsed_date_temporary_column.dt.dayofyear\n",
    "        __data__[f'{date_column_name}_day_of_week'] = parsed_date_temporary_column.dt.dayofweek\n",
    "        __data__[f'{date_column_name}_quarter'] = parsed_date_temporary_column.dt.quarter\n",
    "\n",
    "        log.debug(f'Extracted time series features from column \"{date_column_name}\" and dropped the original column.')\n",
    "\n",
    "        return __data__\n",
    "\n",
    "    def __replace_missing_values__(self, data: pd.DataFrame, value: int = 0) -> pd.DataFrame:\n",
    "        __data__: pd.DataFrame = data.copy()\n",
    "        __data__ = __data__.fillna(value, inplace=False)\n",
    "        \n",
    "        log.debug(f'Replaced all missing values with {value}.')\n",
    "        \n",
    "        return __data__\n",
    "\n",
    "    def __ensure_columns_exist__(self, data: pd.DataFrame, column_names: list, value: object) -> pd.DataFrame:\n",
    "        __data__: pd.DataFrame = data.copy()\n",
    "\n",
    "        for column_name in column_names:\n",
    "            if column_name in __data__.columns:\n",
    "                continue\n",
    "\n",
    "            log.debug(f'Label column \"{column_name}\" did not exist. Creating it with values {value}.')\n",
    "            __data__[column_name] = value\n",
    "\n",
    "        return __data__\n",
    "\n",
    "    def __get_km_distance_between_coordinates__(self,\n",
    "                                                lat1: float,\n",
    "                                                lng1: float,\n",
    "                                                lat2: float,\n",
    "                                                lng2: float) -> float:  \n",
    "        '''\n",
    "        Reference:\n",
    "            Haversine Formula (https://en.wikipedia.org/wiki/Haversine_formula) to calculate distance between two sets of lat and long coordinates.\n",
    "        '''  \n",
    "        r = 6371  # Average radius of Earth in kilometers.\n",
    "\n",
    "        phi1 = np.radians(lat1)\n",
    "        phi2 = np.radians(lat2)\n",
    "        \n",
    "        delta_phi = np.radians(lat2-lat1)\n",
    "        delta_lambda = np.radians(lng2-lng1)\n",
    "\n",
    "        a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "        d = (r * c) # In kilometers\n",
    "\n",
    "        return d\n",
    "\n",
    "    def __onehot_encode_categorical_columns__(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        __data__: pd.DataFrame = data.copy()\n",
    "        categorical_column_names: list = [c for c in data.columns if 'float' not in str(data[c].dtype).lower() and 'int' not in str(data[c].dtype).lower()]\n",
    "        \n",
    "        if len(categorical_column_names) > 0:\n",
    "            __data__ = pd.get_dummies(__data__, columns=categorical_column_names)\n",
    "            \n",
    "            log.debug(f'One-Hot encoded {len(categorical_column_names)} columns. -> {categorical_column_names}')\n",
    "        \n",
    "        return __data__\n",
    "\n",
    "    def __determine_column_scale__(self, column_data: pd.Series) -> int:\n",
    "        first_column_value_str: str = str(column_data.values[0])\n",
    "        should_scale: bool = column_data.values[0] < 1 and len(first_column_value_str.split('.')[1]) > 1\n",
    "        scale: int = 1\n",
    "        \n",
    "        while should_scale:\n",
    "            scale *= 10\n",
    "            should_scale = len(str(column_data.values[0] * scale).split('.')[1]) > 1\n",
    "\n",
    "        return scale\n",
    "\n",
    "    def apply_sigmoid_scale(self, data: pd.DataFrame, reverse: bool = False, only_scale_less_one_values: bool = True) -> pd.DataFrame:\n",
    "        scale = lambda x, min, max: (x - min) / (max - min)\n",
    "        reverse_scale = lambda y, min, max: y * (max - min) + min\n",
    "        \n",
    "        __data__: pd.DataFrame = data.copy()\n",
    "        float_column_names: list = [c for c in __data__.columns if 'float' in str(__data__[c].dtype)]\n",
    "\n",
    "        for column_name in float_column_names:\n",
    "            column_scale_min_config_key: str = f'scale.sigmoid.column.{column_name}.min'\n",
    "            column_scale_max_config_key: str = f'scale.sigmoid.column.{column_name}.max'\n",
    "            \n",
    "            if reverse:\n",
    "                if column_scale_min_config_key not in self.state_dict or column_scale_max_config_key not in self.state_dict:\n",
    "                    continue\n",
    "                \n",
    "                min: float = self.state_dict[column_scale_min_config_key]\n",
    "                max: float = self.state_dict[column_scale_max_config_key]\n",
    "                __data__[column_name] = __data__[column_name].apply(lambda val: reverse_scale(val, min, max))\n",
    "            else:\n",
    "                if only_scale_less_one_values and __data__[column_name].max() > 1:\n",
    "                    continue\n",
    "                \n",
    "                if len(__data__[column_name].unique()) <= 1:\n",
    "                    continue\n",
    "            \n",
    "                min: float = __data__[column_name].min()\n",
    "                max: float = __data__[column_name].max()\n",
    "                self.state_dict[column_scale_min_config_key] = min\n",
    "                self.state_dict[column_scale_max_config_key] = max\n",
    "                __data__[column_name] = __data__[column_name].apply(lambda val: scale(val, min, max))\n",
    "        \n",
    "        return __data__\n",
    "\n",
    "    def register_custom_featurizer(self, custom_featurizer):\n",
    "        '''\n",
    "        Register a custom featurizer that gets executed at the end of the pipeline.\n",
    "\n",
    "        :param custom_featurizer: func, A featurizer function that accepts a Pandas dataframe (featurized data) and should return an augmented dataframe. Operations are not inplace.\n",
    "        '''\n",
    "        log.info(f'Registered custom featurizer.')\n",
    "        self.custom_featurizers.append(custom_featurizer)\n",
    "\n",
    "    def custom_featurize_distance_between_coordinates(self,\n",
    "                                                      data: pd.DataFrame,\n",
    "                                                      lat1_column_name: str,\n",
    "                                                      lng1_column_name: str,\n",
    "                                                      lat2_column_name: str,\n",
    "                                                      lng2_column_name: str,\n",
    "                                                      output_column_name: str) -> pd.DataFrame:\n",
    "        '''\n",
    "        Return a featurized dataset that created a new column for a distance calculated given coordinates.\n",
    "\n",
    "        :param data: pd.DataFrame, A dataframe to featurize.\n",
    "        :param lat1_column_name: float, Source latitude.\n",
    "        :param lng1_column_name: float, Source longitude.\n",
    "        :param lat2_column_name: float, Target latitude.\n",
    "        :param lng2_column_name: float, Target longitude.\n",
    "        :param output_column_name: str, The name of the column to create and persist the calculated distance(s) to.\n",
    "        '''\n",
    "        __data__: pd.DataFrame = data.copy()\n",
    "        __data__[output_column_name] = __data__.apply(lambda row: self.__get_km_distance_between_coordinates__(lat1=row[lat1_column_name],\n",
    "                                                                                                               lng1=row[lng1_column_name],\n",
    "                                                                                                               lat2=row[lat2_column_name],\n",
    "                                                                                                               lng2=row[lng2_column_name]), axis=1)\n",
    "        __data__ = __data__.drop(columns=[lat1_column_name, lng1_column_name, lat2_column_name, lng2_column_name], inplace=False)\n",
    "        \n",
    "        log.debug(f'Creating feature \"{output_column_name}\" for the distance from {lat1_column_name}:{lng1_column_name} -> {lat2_column_name}:{lng2_column_name}.')\n",
    "        \n",
    "        return __data__\n",
    "\n",
    "    def get_train_test_split(self, featurized_data: pd.DataFrame = None, shuffle_data: bool = False, test_split: float = 0.2) -> list:\n",
    "        '''\n",
    "        Return a list with the training X & Y dataframes and the testing X & Y dataframes who's sizes respects the test_split parameter.\n",
    "\n",
    "        :param data: pd.DataFrame, A dataframe to split.\n",
    "        :param shuffle_data: bool, If True, the data passed in would get shuffled prior to being split.\n",
    "        :param test_split: float, The ratio of data to use for testing.\n",
    "        '''\n",
    "        log.debug(f'Splitting data with a test portion of {test_split} and shuffling of data set to {shuffle_data}.')\n",
    "        \n",
    "        __data__: pd.DataFrame = featurized_data.copy() if featurized_data is not None else self.get_featurized_data()\n",
    "        __data__: pd.DataFrame = __data__ if not shuffle_data else __data__.sample(frac=1)\n",
    "        test_row_count: int = int(__data__.shape[0] * test_split)\n",
    "        \n",
    "        train_split: pd.DataFrame = __data__[:-test_row_count]\n",
    "        test_split: pd.DataFrame = __data__[-test_row_count:]\n",
    "        \n",
    "        train_x: pd.DataFrame = train_split[[c for c in train_split.columns if c not in self.labels_column_names]]\n",
    "        train_y: pd.DataFrame = train_split[self.labels_column_names]\n",
    "        \n",
    "        test_x: pd.DataFrame = test_split[[c for c in test_split.columns if c not in self.labels_column_names]]\n",
    "        test_y: pd.DataFrame = test_split[self.labels_column_names]\n",
    "        \n",
    "        return train_x, train_y, test_x, test_y\n",
    "\n",
    "    def get_featurized_data(self, data: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        '''\n",
    "        Return a featurized Pandas dataframe. This function does not perform inplace featurization.\n",
    "\n",
    "        :param data: pd.DataFrame, A dataframe to featurize. self.original_data can be passed in as the data parameter here.\n",
    "        '''\n",
    "        __data__: pd.DataFrame = data.copy() if data is not None else self.original_data.copy()\n",
    "        __data__ = self.__featurize_date_column__(data=__data__, date_column_name=self.date_column_name)\n",
    "        __data__ = self.__replace_missing_values__(data=__data__)\n",
    "        __data__ = self.__ensure_columns_exist__(data=__data__, column_names=self.labels_column_names, value=-np.inf)\n",
    "        __data__ = self.__onehot_encode_categorical_columns__(data=__data__)\n",
    "\n",
    "        for custom_featurizer in self.custom_featurizers:\n",
    "            __data__ = custom_featurizer(__data__)\n",
    "\n",
    "        __data__ = self.apply_sigmoid_scale(data=__data__)\n",
    "            \n",
    "        return __data__\n",
    "\n",
    "    def get_featurized_data_row(self, **kwargs) -> pd.DataFrame:\n",
    "        '''\n",
    "        Return a featurized Pandas dataframe with a single row.\n",
    "\n",
    "        :param kwargs: dict, Arguments to provide a row value for each of the columns in the dataframe used to initialize the loader.\n",
    "        '''\n",
    "        for column_name in self.original_data.columns:\n",
    "            if column_name not in kwargs and column_name not in self.labels_column_names:\n",
    "                raise Exception(f'No kwarg provided for key \"{column_name}\". This is required due to the column existing with this name in the dataset.')\n",
    "\n",
    "        data = {}\n",
    "\n",
    "        for arg_key in kwargs:\n",
    "            data[arg_key] = [ kwargs[arg_key] ]\n",
    "\n",
    "        for label in self.labels_column_names:\n",
    "            data[label] = -np.inf\n",
    "\n",
    "        return self.get_featurized_data(data=pd.DataFrame(data), drop_unique_only_columns=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0203f9377e450cf3e5fd498dcfe93bad69687b6515d650e7d79a42aa53323e2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
